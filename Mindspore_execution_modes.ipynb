{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In MindSpore there are [two execution modes](https://mindspore.cn/tutorials/en/r1.10/advanced/compute_graph/mode.html#dynamic-and-static-graphs): a static graph mode (GRAPH_MODE) and a dynamic graph mode (PYNATIVE_MODE).\n",
        "\n",
        "*   In dynamic graph mode, also known as python native mode for the way its execution, the program is executed line by line. During the forward execution process, the backward execution graph is generated DNAMICALLY in accordance with the backward propagation principle.\n",
        "\n",
        "*   In static graph mode, when the program is built and executed, firstly the computation  graph of the neural network is generated. After that the computation graph is performed (by the means of all operations in it) .\n",
        "\n",
        "Therefore, when static graph mode is set, the neural network model training and inference performs much faster than in the python native mode. Such a boost is possible due to encapsulated graph optimization and cross-platform running.\n",
        "\n",
        "Lets appeal to example: "
      ],
      "metadata": {
        "id": "DcEKAiACjS8H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8snjZh6eusz",
        "outputId": "cf5c7ff5-240b-4d7e-b00a-325fc207dd36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mindspore==1.9.0 in /usr/local/lib/python3.8/dist-packages (1.9.0)\n",
            "Requirement already satisfied: protobuf>=3.13.0 in /usr/local/lib/python3.8/dist-packages (from mindspore==1.9.0) (3.19.6)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from mindspore==1.9.0) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.5.2 in /usr/local/lib/python3.8/dist-packages (from mindspore==1.9.0) (1.7.3)\n",
            "Requirement already satisfied: asttokens>=2.0.4 in /usr/local/lib/python3.8/dist-packages (from mindspore==1.9.0) (2.2.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from mindspore==1.9.0) (23.0)\n",
            "Requirement already satisfied: psutil>=5.6.1 in /usr/local/lib/python3.8/dist-packages (from mindspore==1.9.0) (5.9.4)\n",
            "Requirement already satisfied: astunparse>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from mindspore==1.9.0) (1.6.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from mindspore==1.9.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from asttokens>=2.0.4->mindspore==1.9.0) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.3->mindspore==1.9.0) (0.38.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: download in /usr/local/lib/python3.8/dist-packages (0.3.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from download) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from download) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from download) (4.64.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->download) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->download) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->download) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->download) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "# Firstly install mindspore 1.9.0\n",
        "#  The specified version is for CPU only. In order to use version for GPU,\n",
        "#  type 'mindspore_gpu==1.9.0'\n",
        "!pip install mindspore==1.9.0\n",
        "!pip install download"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from download import download\n",
        "import numpy as np\n",
        "import mindspore as ms\n",
        "from mindspore import nn, Model, Parameter, Tensor\n",
        "from mindspore.dataset import vision, transforms, MnistDataset\n",
        "from mindspore.common.initializer import Normal\n",
        "from mindspore import dtype as mstype"
      ],
      "metadata": {
        "id": "muM10Kw3hdRZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download MNIST dataset and define preprocessing procedure\n",
        "url = \"https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/\" \\\n",
        "      \"notebook/datasets/MNIST_Data.zip\"\n",
        "\n",
        "download(url, \"./\", kind=\"zip\", replace=True)\n",
        "\n",
        "def proc_dataset(data_path, batch_size=32):\n",
        "    mnist_ds = MnistDataset(data_path, shuffle=True)\n",
        "\n",
        "    # preprocess transformation operations\n",
        "    image_transforms = [\n",
        "        vision.Resize(32),\n",
        "        vision.Rescale(1.0 / 255.0, 0),\n",
        "        vision.Normalize(mean=(0.1307,), std=(0.3081,)),\n",
        "        vision.HWC2CHW()\n",
        "    ]\n",
        "\n",
        "    label_transform = transforms.TypeCast(mstype.int32)\n",
        "\n",
        "    mnist_ds = mnist_ds.map(operations=label_transform, input_columns=\"label\")\n",
        "    mnist_ds = mnist_ds.map(operations=image_transforms, input_columns=\"image\")\n",
        "    mnist_ds = mnist_ds.batch(batch_size, drop_remainder=True)\n",
        "    return mnist_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKVRWivmhouG",
        "outputId": "1ff51410-8716-47c8-d6c2-7b3d72f6f9a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/MNIST_Data.zip (10.3 MB)\n",
            "\n",
            "file_sizes: 100%|██████████████████████████| 10.8M/10.8M [00:01<00:00, 10.2MB/s]\n",
            "Extracting zip file...\n",
            "Successfully downloaded / unzipped to ./\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define simple network structure.\n",
        "class LeNet5(nn.Cell):\n",
        "\n",
        "    def __init__(self, num_class=10, num_channel=1):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(num_channel, 6, 5, pad_mode='valid')\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5, pad_mode='valid')\n",
        "        self.relu = nn.ReLU()\n",
        "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Dense(16 * 5 * 5, 120, weight_init=Normal(0.02))\n",
        "        self.fc2 = nn.Dense(120, 84, weight_init=Normal(0.02))\n",
        "        self.fc3 = nn.Dense(84, num_class, weight_init=Normal(0.02))\n",
        "        self.counted = Parameter(Tensor(np.zeros((1))), requires_grad=False)\n",
        "\n",
        "    def construct(self, x):\n",
        "        if self.counted != Tensor(np.ones((1))):\n",
        "            print(\"\\nThis string is only printed in the PYNATIVE_MODE\\n\")\n",
        "            self.counted = Tensor(np.ones((1)))\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.max_pool2d(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.max_pool2d(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "def create_model():\n",
        "    model = LeNet5()\n",
        "    net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\n",
        "    net_opt = nn.Momentum(model.trainable_params(), learning_rate=0.01, momentum=0.9)\n",
        "    trainer = Model(model, loss_fn=net_loss, optimizer=net_opt, metrics={\"Accuracy\": nn.Accuracy()})\n",
        "    return trainer"
      ],
      "metadata": {
        "id": "4cN0K3dmhr3j"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining callbacks\n",
        "from mindspore import LossMonitor\n",
        "from mindspore import CheckpointConfig, ModelCheckpoint\n",
        "from mindspore import TimeMonitor\n",
        "\n",
        "loss_monitor = LossMonitor(1875)\n",
        "config = CheckpointConfig(save_checkpoint_steps=1875, keep_checkpoint_max=10)\n",
        "time_monitor = TimeMonitor(1875)\n",
        "ckpt_callback = ModelCheckpoint(prefix=\"mnist\", directory=\"./checkpoint\", config=config)"
      ],
      "metadata": {
        "id": "vU5AeaIYh0OH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dynamic graphs are executed through explanation, with dynamic syntax affinity and flexible expression. Why may one need use dynamic graph (python native) mode ? The most obvious answer is: for [debug purpose](https://mindspore.cn/tutorials/en/r1.10/advanced/compute_graph/mode.html#mode-selection). In dynamic graph mode, it is possible to use breakpoints and observe intermediate results of network execution ( [inside](https://mindspore.cn/tutorials/en/r1.10/beginner/quick_start.html#building-network) `def construct(self, input)` method, that encapsulates the construction process of the computational graph. "
      ],
      "metadata": {
        "id": "fq5izCIPrb9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = proc_dataset('MNIST_Data/train')\n",
        "test_dataset = proc_dataset('MNIST_Data/test')\n",
        "\n",
        "# Configuring the dynamic graph mode\n",
        "ms.set_context(mode=ms.PYNATIVE_MODE)\n",
        "\n",
        "trainer = create_model()\n",
        "trainer.train(3, train_dataset, callbacks=[ckpt_callback, loss_monitor, time_monitor])\n",
        "print(\"\\nEvaluation:\\n\")\n",
        "trainer.fit(2, train_dataset, test_dataset, callbacks=[loss_monitor])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENWN-dh-6OeE",
        "outputId": "d88d1dcf-a1a0-4dc9-f97d-eef033b738f9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "This string is only printed in the PYNATIVE_MODE\n",
            "\n",
            "epoch: 1 step: 1875, loss is 0.10879134386777878\n",
            "Train epoch time: 59068.311 ms, per step time: 31.503 ms\n",
            "epoch: 2 step: 1875, loss is 0.04291274771094322\n",
            "Train epoch time: 58152.894 ms, per step time: 31.015 ms\n",
            "epoch: 3 step: 1875, loss is 0.0006521427421830595\n",
            "Train epoch time: 54736.380 ms, per step time: 29.193 ms\n",
            "\n",
            "Evaluation:\n",
            "\n",
            "epoch: 1 step: 1875, loss is 0.00042648648377507925\n",
            "Eval result: epoch 1, metrics: {'Accuracy': 0.9897836538461539}\n",
            "epoch: 2 step: 1875, loss is 0.0011952654458582401\n",
            "Eval result: epoch 2, metrics: {'Accuracy': 0.989082532051282}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pay attention to the first string in the cell output. This line only printed in the python native mode. That's because in static graph mode it is not compiled as the operation of the computation graph."
      ],
      "metadata": {
        "id": "uNVxervDsaa0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In static graph mode, that is the default mode in Mindspore, no breakpoints can be set. That's because of the way of [graph execution](https://mindspore.cn/tutorials/en/r1.10/advanced/compute_graph/mode.html#execution-principle-of-the-static-graph-mode).\n",
        "\n",
        "In static graph mode, MindSpore converts the Python source code into an [intermediate representation](https://mindspore.cn/tutorials/experts/en/r1.10/debug/mindir.html#reading-ir), optimizes the IR graph and executes the optimized graph on the hardware device. Static graphs are executed through just in time (JIT) build"
      ],
      "metadata": {
        "id": "vQwB8aMBrUF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = proc_dataset('MNIST_Data/train')\n",
        "test_dataset = proc_dataset('MNIST_Data/test')\n",
        "\n",
        "# Configuring the static graph mode\n",
        "ms.set_context(mode=ms.GRAPH_MODE)\n",
        "\n",
        "trainer = create_model()\n",
        "trainer.train(3, train_dataset, callbacks=[ckpt_callback, loss_monitor, time_monitor])\n",
        "print(\"\\nEvaluation:\\n\")\n",
        "trainer.fit(2, train_dataset, test_dataset, callbacks=[loss_monitor])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpG2G_1O6gXl",
        "outputId": "d7c77c6b-0ae0-4f98-9c3e-1f75c9c57f5c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 step: 1875, loss is 0.08928205072879791\n",
            "Train epoch time: 43178.599 ms, per step time: 23.029 ms\n",
            "epoch: 2 step: 1875, loss is 0.3162972927093506\n",
            "Train epoch time: 42310.823 ms, per step time: 22.566 ms\n",
            "epoch: 3 step: 1875, loss is 0.025710901245474815\n",
            "Train epoch time: 40802.322 ms, per step time: 21.761 ms\n",
            "\n",
            "Evaluation:\n",
            "\n",
            "epoch: 1 step: 1875, loss is 0.07349871098995209\n",
            "Eval result: epoch 1, metrics: {'Accuracy': 0.9863782051282052}\n",
            "epoch: 2 step: 1875, loss is 0.04860566556453705\n",
            "Eval result: epoch 2, metrics: {'Accuracy': 0.9887820512820513}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From now we can see that execution time is twice less for the static graph mode.\n",
        "\n",
        "\n",
        "MindSpore also supports using [control statements](https://mindspore.cn/tutorials/experts/en/r1.10/network/control_flow.html#process-control-statements) in the static graph mode.\n",
        "This is especially useful when dealing with conditional flows in the computation of the network. For example when implementing custom picewise defined activation functions"
      ],
      "metadata": {
        "id": "JL6n30mEtCvB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  It is possible to combine dynamic and static graphs in a single runtime. For that purpose `ms_function` modifier might be applied to any method object that needs to be executed using static graphs. For [example](https://mindspore.cn/tutorials/en/r1.10/advanced/compute_graph/combine.html#implementation-principle):\n",
        "\n",
        "\n",
        "```\n",
        "class Mul(nn.Cell):\n",
        "    \"\"\"Define a class to implement the x self multiplication.\"\"\"\n",
        "    @ms_function  # Use ms_function to modify the function. This function is executed in static graph mode.\n",
        "    def construct(self, x):\n",
        "        x = x * x\n",
        "        x = x * x\n",
        "        return x\n",
        "ms.set_context(mode=ms.PYNATIVE_MODE)\n",
        "net = Mul()\n",
        "```\n",
        "Such modifier usualy usefull when need to improve the execution speed of forward computing tasks in dynamic graph mode.\n"
      ],
      "metadata": {
        "id": "DzRlC-di383-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another useful way of applying intermediate representation is to investigate errors of network definition. For example, lets consider an orinary shapes mismatch error. In Python native mode the output looks like below:"
      ],
      "metadata": {
        "id": "HzuG4e1n6L3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import mindspore\n",
        "from mindspore import nn, ops, set_context, Tensor, Parameter\n",
        "from mindspore.common.initializer import initializer\n",
        "\n",
        "ms.set_context(mode=ms.PYNATIVE_MODE)\n",
        "ms.set_context(save_graphs=False)\n",
        "\n",
        "class Net(nn.Cell):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.weight = Parameter(initializer('normal', [32, 8]), name=\"weight\")\n",
        "        self.bias = Parameter(initializer('zeros', [4]), name=\"bias\")\n",
        "\n",
        "        self.matmul = ops.MatMul()\n",
        "        self.bias_add = ops.BiasAdd()\n",
        "\n",
        "    def construct(self, x1):\n",
        "        x = self.matmul(x1, self.weight)\n",
        "        x = self.bias_add(x, self.bias)\n",
        "        return x\n",
        "\n",
        "net = Net()\n",
        "x = Tensor(np.arange(3*32).reshape(3, 32), mindspore.float32)\n",
        "out = net(x)\n",
        "print('out', out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5YJkIoU465-e",
        "outputId": "6786083b-1784-4e90-912d-367130a86590"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-5aa99e078678>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmindspore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mindspore/nn/cell.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0m_pynative_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mindspore/nn/cell.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0m_pynative_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m             \u001b[0m_pynative_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mindspore/nn/cell.py\u001b[0m in \u001b[0;36m_run_construct\u001b[0;34m(self, cast_inputs, kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shard_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_forward_hook\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-5aa99e078678>\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self, x1)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mindspore/ops/primitive.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshould_elim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_run_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mindspore/common/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*arg, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_python_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mindspore/ops/primitive.py\u001b[0m in \u001b[0;36m_run_op\u001b[0;34m(obj, op_name, args)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_run_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;34m\"\"\"Single op execution function supported by ge in PyNative mode.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_run_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: For 'BiasAdd', bias[0] shape must be equal to input_x[1] shape when data_format is NHWC or input_x[1] shape, but got bias[0] shape: 4, input_x[1] or input_x[1] shape: 8.\n\n----------------------------------------------------\n- C++ Call Stack: (For framework developers)\n----------------------------------------------------\nmindspore/core/ops/bias_add.cc:72 BiasAddInferShape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So above the only way to understand the error is by using the ValueError text. Value error text doesn't look clear and we must appeal to output sizes (4 and 8) and stack trace in order to resolve the issue.\n",
        "\n",
        "Now let us look at what does static graph mode when facing same error:"
      ],
      "metadata": {
        "id": "Gn8rt6D39O2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import mindspore\n",
        "from mindspore import nn, ops, set_context, Tensor, Parameter\n",
        "from mindspore.common.initializer import initializer\n",
        "\n",
        "ms.set_context(mode=ms.GRAPH_MODE)\n",
        "ms.set_context(save_graphs=False)\n",
        "\n",
        "class Net(nn.Cell):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.weight = Parameter(initializer('normal', [32, 8]), name=\"weight\")\n",
        "        self.bias = Parameter(initializer('zeros', [4]), name=\"bias\")\n",
        "\n",
        "        self.matmul = ops.MatMul()\n",
        "        self.bias_add = ops.BiasAdd()\n",
        "\n",
        "    def construct(self, x1):\n",
        "        x = self.matmul(x1, self.weight)\n",
        "        x = self.bias_add(x, self.bias)\n",
        "        return x\n",
        "\n",
        "net = Net()\n",
        "x = Tensor(np.arange(3*32).reshape(3, 32), mindspore.float32)\n",
        "out = net(x)\n",
        "print('out', out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "0Rw04hx78bBs",
        "outputId": "ad28fc14-1a29-4b06-cf92-482d343fd045"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-3fdb641326b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmindspore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mindspore/nn/cell.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m                 logger.warning(f\"For 'Cell', it's not support hook function in graph mode. If you want to use hook \"\n\u001b[1;32m    595\u001b[0m                                f\"function, please use context.set_context to set pynative mode.\")\n\u001b[0;32m--> 596\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_and_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mindspore/nn/cell.py\u001b[0m in \u001b[0;36mcompile_and_run\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \"\"\"\n\u001b[1;32m    984\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auto_parallel_compile_and_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0mnew_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_args_for_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mindspore/nn/cell.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    954\u001b[0m         \"\"\"\n\u001b[1;32m    955\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamic_shape_inputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamic_shape_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m             _cell_graph_executor.compile(self, *inputs, phase=self.phase, auto_parallel_mode=self._auto_parallel_mode,\n\u001b[0m\u001b[1;32m    957\u001b[0m                                          jit_config_dict=self._jit_config_dict)\n\u001b[1;32m    958\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mindspore/common/api.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, obj, phase, do_convert, auto_parallel_mode, jit_config_dict, *args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mjit_config_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_jit_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjit_config_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_vm_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: For 'BiasAdd', bias[0] shape must be equal to input_x[1] shape when data_format is NHWC or input_x[1] shape, but got bias[0] shape: 4, input_x[1] or input_x[1] shape: 8.\n\n----------------------------------------------------\n- The Traceback of Net Construct Code:\n----------------------------------------------------\nThe function call stack (See file '/content/rank_0/om/analyze_fail.dat' for more details. Get instructions about `analyze_fail.dat` at https://www.mindspore.cn/search?inputValue=analyze_fail.dat):\n# 0 In file <ipython-input-22-3fdb641326b6>:20\n\n----------------------------------------------------\n- C++ Call Stack: (For framework developers)\n----------------------------------------------------\nmindspore/core/ops/bias_add.cc:72 BiasAddInferShape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can find the generated file 'analyze_fail.dat':\n",
        "\n"
      ],
      "metadata": {
        "id": "GfsWwwRd6L8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1.This file shows the parsed IR info when graph evaluating failed to help find the problem.\n",
        "# 2.You can search the last `------------------------>` to the node which is inferred failed.\n",
        "# 3.Refer to https://www.mindspore.cn/search?inputValue=analyze_fail.dat to get more instructions.\n",
        "# ===============================================================================\n",
        "\n",
        "# [No.1] Default_wrapper.284\n",
        "# In file <ipython-input-22-3fdb641326b6>:18/\n",
        "funcgraph fg_284(\n",
        "        %para1 : Tensor(F32)[3, 32]    # x1\n",
        "        , %para2 : Ref[Tensor(F32)][4]    # bias\n",
        "        , %para3 : Ref[Tensor(F32)][32, 8]    # weight\n",
        "    ) {\n",
        "\n",
        "#------------------------> 0\n",
        "    %1 = FuncGraph::fg_285(%para1)    #(Tensor(F32)[3, 32])    # fg_285=Default.285 #scope: Default\n",
        "#[CNode]286\n",
        "    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default\n",
        "      # In file <ipython-input-22-3fdb641326b6>:21/#[CNode]287\n",
        "}\n",
        "# order:\n",
        "#   1: @Default_wrapper.284:[CNode]286{[0]: ValueNode<FuncGraph> Default.285, [1]: x1}\n",
        "#   2: @Default_wrapper.284:[CNode]287{[0]: ValueNode<Primitive> Return, [1]: [CNode]286}\n",
        "\n",
        "\n",
        "# [No.2] Default.285\n",
        "# In file <ipython-input-22-3fdb641326b6>:18/\n",
        "funcgraph fg_285[fg_284](\n",
        "        %para4 : Tensor(F32)[3, 32]    # x1\n",
        "    ) {\n",
        "    %1 : Tensor(F32)[3, 8] = DoSignaturePrimitive::S-Prim-MatMul{prim_type=1}[output_names=[\"output\"], transpose_a=Bool(0), input_names=[\"x1\", \"x2\"], transpose_x2=Bool(0), transpose_x1=Bool(0), transpose_b=Bool(0)](%para4, %para3)    #(Tensor(F32)[3, 32], Ref[Tensor(F32)][32, 8]) #scope: Default\n",
        "      # In file <ipython-input-22-3fdb641326b6>:19/#x\n",
        "\n",
        "#------------------------> 1\n",
        "    %2 = DoSignaturePrimitive::S-Prim-BiasAdd{prim_type=1}[output_names=[\"output\"], format=\"NCHW\", input_names=[\"x\", \"b\"]](%1, %para2)    #(Tensor(F32)[3, 8], Ref[Tensor(F32)][4]) #scope: Default\n",
        "      # In file <ipython-input-22-3fdb641326b6>:20/#x\n",
        "    Primitive::Return{prim_type=1}(%2)    #(Undefined) #scope: Default\n",
        "      # In file <ipython-input-22-3fdb641326b6>:21/#[CNode]288\n",
        "}\n",
        "# order:\n",
        "#   1: @Default.285:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MatMul, [1]: x1, [2]: weight}\n",
        "#   2: @Default.285:x{[0]: ValueNode<DoSignaturePrimitive> S-Prim-BiasAdd, [1]: x, [2]: bias}\n",
        "#   3: @Default.285:[CNode]288{[0]: ValueNode<Primitive> Return, [1]: x}\n",
        "\n",
        "\n",
        "#===============================================================================\n",
        "# num of function graphs in stack: 2/3 (Ignored 1 internal frames)."
      ],
      "metadata": {
        "id": "6XYvD178-8yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In short words the .dat file points to the exact place there error occurs and provides detailed information about the error. But it does require some [prerequisites](https://mindspore.cn/tutorials/experts/en/r1.10/debug/mindir.html#reading-ir) in order to read the IR files.\n",
        "\n",
        "\n",
        "The last '--->' in the faile points to the position where inferring failed.\n",
        "\n",
        "From that we can find the exact shapes mismatch: according to ...(%1, %para2)    #(Tensor(F32)[3, 8], Ref[Tensor(F32)][4]), BiasAdd’s inputs are %1 and %para2. That %1’ with shape [3, 8] and %para2 with shape [4] doesn’t meet the requirement about bias (Tensor) - The bias tensor, with shape (C). C must be the same as channel dimension C of input_x... for BiasAdd API. Thus, an error happens."
      ],
      "metadata": {
        "id": "qMDd2cGaAB5Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To resolve the error we need correct shape of the bias parameter:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "...\n",
        "self.bias = Parameter(initializer('zeros', [8]), name=\"bias\")\n",
        "...\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "sRUU--i9AxXe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other useful features of IR files (.ir, .dat and .dot) is that they allow to track all the [phases](https://mindspore.cn/tutorials/experts/en/r1.10/debug/mindir.html#saving-ir) that were performed during computation graph compilation. Moreover, the .dot file might be [vizualized](https://mindspore.cn/tutorials/experts/en/r1.10/debug/mindir.html#dot-introduction) by certain tools.\n",
        "\n"
      ],
      "metadata": {
        "id": "P2y42Ob5Byco"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lr8h0D2aDTvQ"
      }
    }
  ]
}